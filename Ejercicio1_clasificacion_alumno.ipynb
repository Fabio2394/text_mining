{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabio2394/text_mining/blob/main/Ejercicio1_clasificacion_alumno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M5MhVlxlKxJF",
        "outputId": "ee9783ed-5ba8-4672-b7ba-89f1ebd8c0c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2023.9.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.9.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: fsspec==2023.9.2 in /usr/local/lib/python3.11/dist-packages (2023.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install fsspec==2023.9.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5dffd1b"
      },
      "source": [
        "\n",
        "⚙️ **Requerimientos importantes sobre el ejercicio**\n",
        "\n",
        "- El notebook debe ejecutarse **de principio a fin sin intervención manual**.\n",
        "- Si utilizas librerías que no están incluidas por defecto en Google Colab, **asegúrate de instalarlas dentro del notebook** (por ejemplo: `!pip install ...`).\n",
        "\n",
        "- Algunas celdas incluyen identificadores especiales que indican ciertas normas que **debes** respetar:\n",
        " - `#NO-MODIFY: DATA LOAD`  \n",
        "    🔒 **No modifiques** el contenido de esta celda.\n",
        "\n",
        "  - `#NO-MODIFY: VARIABLE NAME`  \n",
        "    ✏️ Puedes modificar o añadir información **dentro de la celda**, pero **sin cambiar el nombre de la variable asignada**. No incluyas más variables de las existentes en la celda.\n",
        "\n",
        "  - `#MODIFY: ADD INFO TO SOLVE FUNCTION`  \n",
        "    🔧 Puedes modificar el **interior de la función** para resolver la tarea, pero **no cambies su nombre, la cabecera ni el `return`**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w1C3ZBXHL0b"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7WTXfHYTHQmo",
        "outputId": "2e07d492-0a0d-4aa8-9ebd-0f4ce37156c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-51700642.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_shell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;31m# Aliases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2475\u001b[0;31m \u001b[0m_downloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2476\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, server_index_url, download_dir)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# decide where we're going to save things to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_download_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;31m# /////////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdefault_download_dir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;31m# Check if we have sufficient permissions to install in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;31m# variety of system-wide locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnltkdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltkdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltkdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnltkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5xkvK9cHSse"
      },
      "outputs": [],
      "source": [
        "# Add your imports here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1KKTZUcH_xk"
      },
      "source": [
        "# 🔍 Ejercicio1: Detección de profesiones en tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enunciado"
      ],
      "metadata": {
        "id": "gLDLR2bEHk2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejercicio vamos a trabajar con un conjunto de datos procedente de medios sociales online.\n",
        "\n",
        "Utilizaremos un subconjunto de los datos de la tarea 1 del shared task [**ProfNER**](https://temu.bsc.es/smm4h-spanish), centrada en la detección de menciones a profesiones en tweets publicados durante la pandemia del COVID-19. El objetivo original de la tarea era analizar que profesiones podrían haber sido especialmente vulnerables en el contexto de la crisis sanitaria.\n",
        "\n",
        "Para simplificar el ejercicio, he preparado una versión reducida del dataset original. Tu tarea será entrenar un clasificador binario basado en la arquitectura Transformers, que, dado un tweet, determine si contiene una mención explícita a una profesión (etiqueta `1`) o no (etiqueta `0`).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6kx1_gwPQGcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ **Objetivos del ejercicio**\n",
        "\n",
        "A lo largo de este notebook, completarás las siguientes etapas para construir un clasificador de menciones a profesiones en tweets:\n",
        "\n",
        "1. **Análisis Exploratorio de Datos (EDA)**: Calcular estadísticas básicas del conjunto de datos (como el número de ejemplos del training set, la distribución de clases del dataset, la longitud media de los textos) o crear visualizaciones para cmprender mejor el contenido de los documentos usando wordclouds o histogramas.\n",
        "\n",
        "2. **Selección y justificación del modelo**: Elegir un modelo del Hub de Huggingface adecuado para los datos con los que se va a trabajar y el tipo de tarea a desarrollar.\n",
        "\n",
        "3. **Entrenamiento del clasificador**: Entrenar el modelo de forma reproducible y evaluar su rendimiento sobreel conjunto de datos de validación, incluyendo un classification score y matriz de confusion\n",
        "\n",
        "4. **Generación de predicciones sobre el conjunte de test**: Aplicar el modelo entrenado al conjunto de test, y guardar las predicciones en un archivo `.tsv` de 2 columnas `id` y `label` separadas por tabulador"
      ],
      "metadata": {
        "id": "3VHMEt0x-7UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📝 **Criterios de Evaluación**\n",
        "\n",
        "Tu trabajo será evaluado según los siguientes criterios:\n",
        "\n",
        "| Criterio                                            | Peso  |\n",
        "|-----------------------------------------------------|--------|\n",
        "| 🔍 Análisis exploratorio y preprocesamiento         | 20%   |\n",
        "| 🤖 Selección y justificación del modelo             | 25%   |\n",
        "| 📁 Formato y validez del archivo de predicciones    | 5%    |\n",
        "| ⚙️ Ejecución correcta del notebook (sin intervención) | 10%   |\n",
        "| 📈 Rendimiento del modelo sobre el conjunto de test | 30%   |\n",
        "| ✍️ Claridad y calidad de las explicaciones          | 10%   |\n",
        "\n",
        "\n",
        "\n",
        "🔔 **Nota importante:**\n",
        "\n",
        "> El rendimiento del modelo se evaluará utilizando métricas estándar como el **F1-score** sobre el conjunto de test.\n",
        "\n",
        "> El archivo de predicciones debe respetar **estrictamente** el formato solicitado (`id` y `label`, separados por tabulador y con extensión `.tsv`).  \n",
        "  ❗ Si el archivo no cumple con este formato, **el ejercicio no podrá ser evaluado en esa sección**.\n",
        "\n",
        "> El/la estudiante con el **mayor F1-score** obtendrá la puntuación máxima en el apartado de rendimiento. El resto de calificaciones se ajustarán de forma proporcional al mejor resultado\n"
      ],
      "metadata": {
        "id": "VPaXLRNeAElo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "⚙️ **Requerimientos y reglas**\n",
        "\n",
        "- El notebook debe ejecutarse **de principio a fin sin intervención manual**.\n",
        "- Si utilizas librerías que no están incluidas por defecto en Google Colab, **asegúrate de instalarlas dentro del notebook** (por ejemplo: `!pip install ...`).\n",
        "\n",
        "- Algunas celdas incluyen identificadores especiales que indican ciertas normas que **debes** respetar:\n",
        " - `#NO-MODIFY: DATA LOAD`  \n",
        "    🔒 **No modifiques** el contenido de esta celda.\n",
        "\n",
        "  - `#NO-MODIFY: VARIABLE NAME`  \n",
        "    ✏️ Puedes modificar o añadir información **dentro de la celda**, pero **sin cambiar el nombre de la variable asignada**. No incluyas más variables de las existentes en la celda.\n",
        "\n",
        "  - `#MODIFY: ADD INFO TO SOLVE FUNCTION`  \n",
        "    🔧 Puedes modificar el **interior de la función** para resolver la tarea, pero **no cambies su nombre, la cabecera ni el `return`**.\n"
      ],
      "metadata": {
        "id": "3M19bykxA0ZP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj9IcJEwIB91"
      },
      "source": [
        "# Tu resolución (rellena las celdas marcadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOXm4JVwIElL"
      },
      "source": [
        "## Obtención de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos los datos del [repositorio de Huggingface](https://huggingface.co/datasets/luisgasco/profner_classification_master)."
      ],
      "metadata": {
        "id": "gtOwX5HKCSfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aiOIGd78IG3y"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: DATA LOAD\n",
        "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n",
        "dataset = load_dataset(\"luisgasco/profner_classification_master\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset contiene tres subsets:\n",
        "- **train** y **validation**: Contienen el identificador del tweet, el texto, y su etiqueta, que podrá tener valor 1, si contiene una mención de una profesión; o valor 0, si no contiene una mención de una profesión.\n",
        "- **test**: El test set tambiíen contiene la información de label por un requerimiento de Huggingface, pero el contenido de esta variable es siempre \"-1\". Es decir que deberéis predecir nuevas etiquetas una vez hayáis entrenado el modelo utilizando el train y el validation set."
      ],
      "metadata": {
        "id": "nY-vjg88CfpW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163nmdUnIG-P"
      },
      "source": [
        "## Análisis exploratorio de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para hacer el análisis exploratorio de datos, transformamos cada subset a un pandas dataframe para mayor comodidad."
      ],
      "metadata": {
        "id": "umz-kP7yDDkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkphOXpCIhqj"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: DATA LOAD\n",
        "dataset_train_df = dataset[\"train\"].to_pandas()\n",
        "dataset_val_df = dataset[\"validation\"].to_pandas()\n",
        "dataset_test_df = dataset[\"test\"].to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Número de documentos**\n",
        "\n",
        "Obten con la función `get_num_docs_evaluation()` el número de documentos del dataset de training y validation.\n",
        "\n",
        "> Recuerda incorporar la información para el cálculo dentro del a siguiente celda, sin modificar los atributos de entrada ni de salida de la función, ni su nombre."
      ],
      "metadata": {
        "id": "kJ4lLzjODJTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MODIFY: ADD INFO TO SOLVE FUNCTION\n",
        "def get_num_docs_evaluation(dataset_df):\n",
        "  # Modifica la función.\n",
        "\n",
        "  # No modifiques el return\n",
        "  return num_docs\n"
      ],
      "metadata": {
        "id": "8v9AXqgMEh0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez generada la función, puedes utilizarla posteriormente para calcular resultados y comentarlos"
      ],
      "metadata": {
        "id": "PVxQg5u_FPlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica la función\n"
      ],
      "metadata": {
        "id": "5l82IvmOFUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Número de documentos duplicados**\n",
        "\n",
        "Obten con la función `detect_duplicates_evaluation()` el número de documentos duplicados del dataset de training y validation.\n",
        "\n",
        "> Recuerda incorporar la información para el cálculo dentro del a siguiente celda, sin modificar los atributos de entrada ni de salida de la función, ni su nombre."
      ],
      "metadata": {
        "id": "TrxV3XkcFYhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_cviBv-IxHJ"
      },
      "outputs": [],
      "source": [
        "#MODIFY: ADD INFO TO SOLVE FUNCTION\n",
        "def detect_duplicates_evaluation(dataset_df):\n",
        "  # Modifica la función.\n",
        "\n",
        "  # No modifiques el return\n",
        "  return num_duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez generada la función, puedes utilizarla posteriormente para calcular resultados y comentarlos"
      ],
      "metadata": {
        "id": "y_4zYMnOFjhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica la función"
      ],
      "metadata": {
        "id": "4AgUKaVQFjhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZq8ZXzkJk0t"
      },
      "source": [
        "**Número de documentos por cada clase:**\n",
        "\n",
        "\n",
        "Obten con la función `analyse_num_labels_evaluation()` para calcular el número de documentos de cada categoría en el dataset\n",
        "\n",
        "> Recuerda incorporar la información para el cálculo dentro del a siguiente celda, sin modificar los atributos de entrada ni de salida de la función, ni su nombre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvfd9yVVJo6-"
      },
      "outputs": [],
      "source": [
        "#MODIFY: ADD INFO TO SOLVE FUNCTION\n",
        "def analyse_num_labels_evaluation(dataset_df):\n",
        "  # Modifica la función.\n",
        "\n",
        "  # No modifiques el return\n",
        "  return num_positives, num_negatives"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez generada la función, puedes utilizarla posteriormente para calcular resultados y comentarlos"
      ],
      "metadata": {
        "id": "zuRURsOqGVF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica la función\n"
      ],
      "metadata": {
        "id": "IUx_-_wFGVGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxXknuNvKK8f"
      },
      "source": [
        "**Distribución de la longitud de los tweet en caracteres:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_rLDRgCKU8j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrtI16QKKNZq"
      },
      "source": [
        "**Análisis de contenido de los tweets**\n",
        "\n",
        "Para ello utiliza wordclouds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZCi84lYK4jW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FZUV6mSIJO1"
      },
      "source": [
        "## Tokenización"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El texto del dataset no está preparado para ser introducido en un modelo Transformers. Lleva a cabo el proceso de tokenización."
      ],
      "metadata": {
        "id": "61YNAqIAG3aq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGA4Rz7UIDUz"
      },
      "outputs": [],
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecciona un modelo apropiado para la tarea:"
      ],
      "metadata": {
        "id": "kGZStD5MHBuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Recuerda que en la siguiente celda sólo debes asignar un valor a model_name. No añadas más información en la celda."
      ],
      "metadata": {
        "id": "famSsepTHJPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svQiqzz_Lywz"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: VARIABLE NAME\n",
        "model_name = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes continuar con el proceso aquí:"
      ],
      "metadata": {
        "id": "lMivggEnHQqY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6CH_9QpW6IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUel8a-FN0nB"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga el model para ser ajustado posteriormente:"
      ],
      "metadata": {
        "id": "cOb2YTABXDv5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzfR_vm5XHOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeUuTSJpN9pN"
      },
      "source": [
        "### Configuracion training_args"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configura los parámetros de entrenamiento del modelo.\n",
        "\n",
        "\n",
        ">"
      ],
      "metadata": {
        "id": "0Iy9mSLIIkju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Recuerda que en la siguiente celda sólo debes asignar atributos a la variable training_args. No añadas  otras variables en la celda"
      ],
      "metadata": {
        "id": "ucWL18iUIqme"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mexUYxXoN9v7"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: VARIABLE NAME\n",
        "training_args = TrainingArguments(\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LosxnaBOIto"
      },
      "source": [
        "### Métricas de evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define las métricas de evaluación"
      ],
      "metadata": {
        "id": "Xkg3xIBBIzdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99-S1UCeOLAH"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YFV7ugfOMtr"
      },
      "source": [
        "### Ajuste del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lleva a cabo el ajuste del modelo:"
      ],
      "metadata": {
        "id": "62fSC9hEI3ih"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OYXvp-KOQ2J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hi38oUIOevr"
      },
      "source": [
        "## Evaluacion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez llevada a cabo el entrenamiento, realiza la evaluación del modelo."
      ],
      "metadata": {
        "id": "OPYzfaRRI-Ez"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEOk5u3GXOhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genera predicciones"
      ],
      "metadata": {
        "id": "Sf1-X0ozH1x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genera predicciones sobre el test set. Recuerda que el archivo que generes y adjuntes al ejercicio debe tener dos columnas:\n",
        "\n",
        "\n",
        "| id         | label |\n",
        "|------------|-------|\n",
        "| 1234567890 | 1     |\n",
        "| 1234567891 | 0     |\n",
        "| 1234567892 | 0     |\n",
        "| 1234567893 | 1     |\n",
        "\n",
        "- El archivo debe estar en formato **TSV** (separado por tabuladores).\n",
        "- Debe contener exactamente **dos columnas**: `id` y `label`.\n",
        "- Es obligatorio incluir la **cabecera**.\n"
      ],
      "metadata": {
        "id": "4GyrGKTfJUIo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qf7sQSH_XQ20"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}