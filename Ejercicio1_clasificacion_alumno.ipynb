{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabio2394/text_mining/blob/main/Ejercicio1_clasificacion_alumno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M5MhVlxlKxJF",
        "outputId": "ee9783ed-5ba8-4672-b7ba-89f1ebd8c0c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2023.9.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.4)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.9.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: fsspec==2023.9.2 in /usr/local/lib/python3.11/dist-packages (2023.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install fsspec==2023.9.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5dffd1b"
      },
      "source": [
        "\n",
        "‚öôÔ∏è **Requerimientos importantes sobre el ejercicio**\n",
        "\n",
        "- El notebook debe ejecutarse **de principio a fin sin intervenci√≥n manual**.\n",
        "- Si utilizas librer√≠as que no est√°n incluidas por defecto en Google Colab, **aseg√∫rate de instalarlas dentro del notebook** (por ejemplo: `!pip install ...`).\n",
        "\n",
        "- Algunas celdas incluyen identificadores especiales que indican ciertas normas que **debes** respetar:\n",
        " - `#NO-MODIFY: DATA LOAD`  \n",
        "    üîí **No modifiques** el contenido de esta celda.\n",
        "\n",
        "  - `#NO-MODIFY: VARIABLE NAME`  \n",
        "    ‚úèÔ∏è Puedes modificar o a√±adir informaci√≥n **dentro de la celda**, pero **sin cambiar el nombre de la variable asignada**. No incluyas m√°s variables de las existentes en la celda.\n",
        "\n",
        "  - `#MODIFY: ADD INFO TO SOLVE FUNCTION`  \n",
        "    üîß Puedes modificar el **interior de la funci√≥n** para resolver la tarea, pero **no cambies su nombre, la cabecera ni el `return`**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w1C3ZBXHL0b"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7WTXfHYTHQmo",
        "outputId": "2e07d492-0a0d-4aa8-9ebd-0f4ce37156c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-51700642.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_shell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m \u001b[0;31m# Aliases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2475\u001b[0;31m \u001b[0m_downloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2476\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, server_index_url, download_dir)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# decide where we're going to save things to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_download_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;31m# /////////////////////////////////////////////////////////////////\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdefault_download_dir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;31m# Check if we have sufficient permissions to install in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;31m# variety of system-wide locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnltkdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltkdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltkdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnltkdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5xkvK9cHSse"
      },
      "outputs": [],
      "source": [
        "# Add your imports here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1KKTZUcH_xk"
      },
      "source": [
        "# üîç Ejercicio1: Detecci√≥n de profesiones en tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enunciado"
      ],
      "metadata": {
        "id": "gLDLR2bEHk2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejercicio vamos a trabajar con un conjunto de datos procedente de medios sociales online.\n",
        "\n",
        "Utilizaremos un subconjunto de los datos de la tarea 1 del shared task [**ProfNER**](https://temu.bsc.es/smm4h-spanish), centrada en la detecci√≥n de menciones a profesiones en tweets publicados durante la pandemia del COVID-19. El objetivo original de la tarea era analizar que profesiones podr√≠an haber sido especialmente vulnerables en el contexto de la crisis sanitaria.\n",
        "\n",
        "Para simplificar el ejercicio, he preparado una versi√≥n reducida del dataset original. Tu tarea ser√° entrenar un clasificador binario basado en la arquitectura Transformers, que, dado un tweet, determine si contiene una menci√≥n expl√≠cita a una profesi√≥n (etiqueta `1`) o no (etiqueta `0`).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6kx1_gwPQGcp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ **Objetivos del ejercicio**\n",
        "\n",
        "A lo largo de este notebook, completar√°s las siguientes etapas para construir un clasificador de menciones a profesiones en tweets:\n",
        "\n",
        "1. **An√°lisis Exploratorio de Datos (EDA)**: Calcular estad√≠sticas b√°sicas del conjunto de datos (como el n√∫mero de ejemplos del training set, la distribuci√≥n de clases del dataset, la longitud media de los textos) o crear visualizaciones para cmprender mejor el contenido de los documentos usando wordclouds o histogramas.\n",
        "\n",
        "2. **Selecci√≥n y justificaci√≥n del modelo**: Elegir un modelo del Hub de Huggingface adecuado para los datos con los que se va a trabajar y el tipo de tarea a desarrollar.\n",
        "\n",
        "3. **Entrenamiento del clasificador**: Entrenar el modelo de forma reproducible y evaluar su rendimiento sobreel conjunto de datos de validaci√≥n, incluyendo un classification score y matriz de confusion\n",
        "\n",
        "4. **Generaci√≥n de predicciones sobre el conjunte de test**: Aplicar el modelo entrenado al conjunto de test, y guardar las predicciones en un archivo `.tsv` de 2 columnas `id` y `label` separadas por tabulador"
      ],
      "metadata": {
        "id": "3VHMEt0x-7UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù **Criterios de Evaluaci√≥n**\n",
        "\n",
        "Tu trabajo ser√° evaluado seg√∫n los siguientes criterios:\n",
        "\n",
        "| Criterio                                            | Peso  |\n",
        "|-----------------------------------------------------|--------|\n",
        "| üîç An√°lisis exploratorio y preprocesamiento         | 20%   |\n",
        "| ü§ñ Selecci√≥n y justificaci√≥n del modelo             | 25%   |\n",
        "| üìÅ Formato y validez del archivo de predicciones    | 5%    |\n",
        "| ‚öôÔ∏è Ejecuci√≥n correcta del notebook (sin intervenci√≥n) | 10%   |\n",
        "| üìà Rendimiento del modelo sobre el conjunto de test | 30%   |\n",
        "| ‚úçÔ∏è Claridad y calidad de las explicaciones          | 10%   |\n",
        "\n",
        "\n",
        "\n",
        "üîî **Nota importante:**\n",
        "\n",
        "> El rendimiento del modelo se evaluar√° utilizando m√©tricas est√°ndar como el **F1-score** sobre el conjunto de test.\n",
        "\n",
        "> El archivo de predicciones debe respetar **estrictamente** el formato solicitado (`id` y `label`, separados por tabulador y con extensi√≥n `.tsv`).  \n",
        "  ‚ùó Si el archivo no cumple con este formato, **el ejercicio no podr√° ser evaluado en esa secci√≥n**.\n",
        "\n",
        "> El/la estudiante con el **mayor F1-score** obtendr√° la puntuaci√≥n m√°xima en el apartado de rendimiento. El resto de calificaciones se ajustar√°n de forma proporcional al mejor resultado\n"
      ],
      "metadata": {
        "id": "VPaXLRNeAElo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "‚öôÔ∏è **Requerimientos y reglas**\n",
        "\n",
        "- El notebook debe ejecutarse **de principio a fin sin intervenci√≥n manual**.\n",
        "- Si utilizas librer√≠as que no est√°n incluidas por defecto en Google Colab, **aseg√∫rate de instalarlas dentro del notebook** (por ejemplo: `!pip install ...`).\n",
        "\n",
        "- Algunas celdas incluyen identificadores especiales que indican ciertas normas que **debes** respetar:\n",
        " - `#NO-MODIFY: DATA LOAD`  \n",
        "    üîí **No modifiques** el contenido de esta celda.\n",
        "\n",
        "  - `#NO-MODIFY: VARIABLE NAME`  \n",
        "    ‚úèÔ∏è Puedes modificar o a√±adir informaci√≥n **dentro de la celda**, pero **sin cambiar el nombre de la variable asignada**. No incluyas m√°s variables de las existentes en la celda.\n",
        "\n",
        "  - `#MODIFY: ADD INFO TO SOLVE FUNCTION`  \n",
        "    üîß Puedes modificar el **interior de la funci√≥n** para resolver la tarea, pero **no cambies su nombre, la cabecera ni el `return`**.\n"
      ],
      "metadata": {
        "id": "3M19bykxA0ZP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj9IcJEwIB91"
      },
      "source": [
        "# Tu resoluci√≥n (rellena las celdas marcadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOXm4JVwIElL"
      },
      "source": [
        "## Obtenci√≥n de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descargamos los datos del [repositorio de Huggingface](https://huggingface.co/datasets/luisgasco/profner_classification_master)."
      ],
      "metadata": {
        "id": "gtOwX5HKCSfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aiOIGd78IG3y"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: DATA LOAD\n",
        "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel\n",
        "dataset = load_dataset(\"luisgasco/profner_classification_master\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset contiene tres subsets:\n",
        "- **train** y **validation**: Contienen el identificador del tweet, el texto, y su etiqueta, que podr√° tener valor 1, si contiene una menci√≥n de una profesi√≥n; o valor 0, si no contiene una menci√≥n de una profesi√≥n.\n",
        "- **test**: El test set tambi√≠en contiene la informaci√≥n de label por un requerimiento de Huggingface, pero el contenido de esta variable es siempre \"-1\". Es decir que deber√©is predecir nuevas etiquetas una vez hay√°is entrenado el modelo utilizando el train y el validation set."
      ],
      "metadata": {
        "id": "nY-vjg88CfpW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163nmdUnIG-P"
      },
      "source": [
        "## An√°lisis exploratorio de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para hacer el an√°lisis exploratorio de datos, transformamos cada subset a un pandas dataframe para mayor comodidad."
      ],
      "metadata": {
        "id": "umz-kP7yDDkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkphOXpCIhqj"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: DATA LOAD\n",
        "dataset_train_df = dataset[\"train\"].to_pandas()\n",
        "dataset_val_df = dataset[\"validation\"].to_pandas()\n",
        "dataset_test_df = dataset[\"test\"].to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N√∫mero de documentos**\n",
        "\n",
        "Obten con la funci√≥n `get_num_docs_evaluation()` el n√∫mero de documentos del dataset de training y validation.\n",
        "\n",
        "> Recuerda incorporar la informaci√≥n para el c√°lculo dentro del a siguiente celda, sin modificar los atributos de entrada ni de salida de la funci√≥n, ni su nombre."
      ],
      "metadata": {
        "id": "kJ4lLzjODJTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MODIFY: ADD INFO TO SOLVE FUNCTION\n",
        "def get_num_docs_evaluation(dataset_df):\n",
        "  # Modifica la funci√≥n.\n",
        "\n",
        "  # No modifiques el return\n",
        "  return num_docs\n"
      ],
      "metadata": {
        "id": "8v9AXqgMEh0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez generada la funci√≥n, puedes utilizarla posteriormente para calcular resultados y comentarlos"
      ],
      "metadata": {
        "id": "PVxQg5u_FPlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica la funci√≥n\n"
      ],
      "metadata": {
        "id": "5l82IvmOFUBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N√∫mero de documentos duplicados**\n",
        "\n",
        "Obten con la funci√≥n `detect_duplicates_evaluation()` el n√∫mero de documentos duplicados del dataset de training y validation.\n",
        "\n",
        "> Recuerda incorporar la informaci√≥n para el c√°lculo dentro del a siguiente celda, sin modificar los atributos de entrada ni de salida de la funci√≥n, ni su nombre."
      ],
      "metadata": {
        "id": "TrxV3XkcFYhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_cviBv-IxHJ"
      },
      "outputs": [],
      "source": [
        "#MODIFY: ADD INFO TO SOLVE FUNCTION\n",
        "def detect_duplicates_evaluation(dataset_df):\n",
        "  # Modifica la funci√≥n.\n",
        "\n",
        "  # No modifiques el return\n",
        "  return num_duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez generada la funci√≥n, puedes utilizarla posteriormente para calcular resultados y comentarlos"
      ],
      "metadata": {
        "id": "y_4zYMnOFjhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica la funci√≥n"
      ],
      "metadata": {
        "id": "4AgUKaVQFjhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZq8ZXzkJk0t"
      },
      "source": [
        "**N√∫mero de documentos por cada clase:**\n",
        "\n",
        "\n",
        "Obten con la funci√≥n `analyse_num_labels_evaluation()` para calcular el n√∫mero de documentos de cada categor√≠a en el dataset\n",
        "\n",
        "> Recuerda incorporar la informaci√≥n para el c√°lculo dentro del a siguiente celda, sin modificar los atributos de entrada ni de salida de la funci√≥n, ni su nombre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvfd9yVVJo6-"
      },
      "outputs": [],
      "source": [
        "#MODIFY: ADD INFO TO SOLVE FUNCTION\n",
        "def analyse_num_labels_evaluation(dataset_df):\n",
        "  # Modifica la funci√≥n.\n",
        "\n",
        "  # No modifiques el return\n",
        "  return num_positives, num_negatives"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez generada la funci√≥n, puedes utilizarla posteriormente para calcular resultados y comentarlos"
      ],
      "metadata": {
        "id": "zuRURsOqGVF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica la funci√≥n\n"
      ],
      "metadata": {
        "id": "IUx_-_wFGVGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxXknuNvKK8f"
      },
      "source": [
        "**Distribuci√≥n de la longitud de los tweet en caracteres:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_rLDRgCKU8j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrtI16QKKNZq"
      },
      "source": [
        "**An√°lisis de contenido de los tweets**\n",
        "\n",
        "Para ello utiliza wordclouds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZCi84lYK4jW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FZUV6mSIJO1"
      },
      "source": [
        "## Tokenizaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El texto del dataset no est√° preparado para ser introducido en un modelo Transformers. Lleva a cabo el proceso de tokenizaci√≥n."
      ],
      "metadata": {
        "id": "61YNAqIAG3aq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGA4Rz7UIDUz"
      },
      "outputs": [],
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecciona un modelo apropiado para la tarea:"
      ],
      "metadata": {
        "id": "kGZStD5MHBuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Recuerda que en la siguiente celda s√≥lo debes asignar un valor a model_name. No a√±adas m√°s informaci√≥n en la celda."
      ],
      "metadata": {
        "id": "famSsepTHJPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svQiqzz_Lywz"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: VARIABLE NAME\n",
        "model_name = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes continuar con el proceso aqu√≠:"
      ],
      "metadata": {
        "id": "lMivggEnHQqY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6CH_9QpW6IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUel8a-FN0nB"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga el model para ser ajustado posteriormente:"
      ],
      "metadata": {
        "id": "cOb2YTABXDv5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzfR_vm5XHOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeUuTSJpN9pN"
      },
      "source": [
        "### Configuracion training_args"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configura los par√°metros de entrenamiento del modelo.\n",
        "\n",
        "\n",
        ">"
      ],
      "metadata": {
        "id": "0Iy9mSLIIkju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Recuerda que en la siguiente celda s√≥lo debes asignar atributos a la variable training_args. No a√±adas  otras variables en la celda"
      ],
      "metadata": {
        "id": "ucWL18iUIqme"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mexUYxXoN9v7"
      },
      "outputs": [],
      "source": [
        "#NO-MODIFY: VARIABLE NAME\n",
        "training_args = TrainingArguments(\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LosxnaBOIto"
      },
      "source": [
        "### M√©tricas de evaluaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define las m√©tricas de evaluaci√≥n"
      ],
      "metadata": {
        "id": "Xkg3xIBBIzdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99-S1UCeOLAH"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YFV7ugfOMtr"
      },
      "source": [
        "### Ajuste del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lleva a cabo el ajuste del modelo:"
      ],
      "metadata": {
        "id": "62fSC9hEI3ih"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OYXvp-KOQ2J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hi38oUIOevr"
      },
      "source": [
        "## Evaluacion"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez llevada a cabo el entrenamiento, realiza la evaluaci√≥n del modelo."
      ],
      "metadata": {
        "id": "OPYzfaRRI-Ez"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEOk5u3GXOhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Genera predicciones"
      ],
      "metadata": {
        "id": "Sf1-X0ozH1x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genera predicciones sobre el test set. Recuerda que el archivo que generes y adjuntes al ejercicio debe tener dos columnas:\n",
        "\n",
        "\n",
        "| id         | label |\n",
        "|------------|-------|\n",
        "| 1234567890 | 1     |\n",
        "| 1234567891 | 0     |\n",
        "| 1234567892 | 0     |\n",
        "| 1234567893 | 1     |\n",
        "\n",
        "- El archivo debe estar en formato **TSV** (separado por tabuladores).\n",
        "- Debe contener exactamente **dos columnas**: `id` y `label`.\n",
        "- Es obligatorio incluir la **cabecera**.\n"
      ],
      "metadata": {
        "id": "4GyrGKTfJUIo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qf7sQSH_XQ20"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}